{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! In this programming assignment you need to refresh your `pandas` knowledge. You will need to do several [`groupby`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)s and [`join`]()`s to solve the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/'\n",
    "\n",
    "transactions    = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'))\n",
    "items           = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "item_categories = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))\n",
    "shops           = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use is taken from the competition, that serves as the final project for this course. You can find complete data description at the [competition web page](https://www.kaggle.com/c/competitive-data-science-final-project/data). To join the competition use [this link](https://www.kaggle.com/t/1ea93815dca248e99221df42ebde3540)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple task. \n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li><b>Print the shape of the loaded dataframes and use [`df.head`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html) function to print several rows. Examine the features you are given.</b></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Transaction shape: {transactions.shape}, head is:\")\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Items shape: {items.shape}, head is:\")\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Item categories shape: {item_categories.shape}, head is:\")\n",
    "item_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Shops shape: {shops.shape}, head is:\")\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your `pandas` skills to get answers for the following questions. \n",
    "The first question is:\n",
    "\n",
    "1. ** What was the maximum total revenue among all the shops in September, 2014?** \n",
    "\n",
    "\n",
    "* Hereinafter *revenue* refers to total sales minus value of goods returned.\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "* Sometimes items are returned, find such examples in the dataset. \n",
    "* It is handy to split `date` field into [`day`, `month`, `year`] components and use `df.year == 14` and `df.month == 9` in order to select target subset of dates.\n",
    "* You may work with `date` feature as with strings, or you may first convert it to `pd.datetime` type with `pd.to_datetime` function, but do not forget to set correct `format` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['item_value'] = transactions.item_price * transactions.item_cnt_day\n",
    "transactions.datetime = pd.to_datetime(transactions.date, format=\"%d.%m.%Y\")\n",
    "\n",
    "mask = (transactions.datetime >= '2014-09-01') & (transactions.datetime <= '2014-09-30')\n",
    "\n",
    "max_revenue = transactions.loc[mask].groupby(\"shop_id\").item_value.sum().max()\n",
    "max_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's move on and answer another question:\n",
    "\n",
    "<ol start=\"2\">\n",
    "  <li><b>What item category generated the highest revenue in summer 2014?</b></li>\n",
    "</ol>\n",
    "\n",
    "* Submit `id` of the category found.\n",
    "    \n",
    "* Here we call \"summer\" the period from June to August.\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "* Note, that for an object `x` of type `pd.Series`: `x.argmax()` returns **index** of the maximum element. `pd.Series` can have non-trivial index (not `[1, 2, 3, ... ]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.datetime = pd.to_datetime(transactions.date, format=\"%d.%m.%Y\")\n",
    "mask = (transactions.datetime >= '2014-06-01') & (transactions.datetime <= '2014-08-31')\n",
    "\n",
    "june_august_transactions = transactions.loc[mask]\n",
    "joined_df = june_august_transactions[[\"item_id\", \"item_value\"]] \\\n",
    "    .join(items.set_index(\"item_id\"), on=\"item_id\", how='left')\n",
    "revenue_per_cat = joined_df.groupby(by=\"item_category_id\")['item_value'].sum().reset_index()\n",
    "\n",
    "category_id_with_max_revenue = revenue_per_cat.loc[revenue_per_cat['item_value'].argmax()].item_category_id\n",
    "category_id_with_max_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "  <li><b>How many items are there, such that their price stays constant (to the best of our knowledge) during the whole period of time?</b></li>\n",
    "</ol>\n",
    "\n",
    "* Let's assume, that the items are returned for the same price as they had been sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_price = transactions.groupby(\"item_id\")[\"item_price\"].nunique()\n",
    "\n",
    "num_items_constant_price = unique_price.loc[unique_price == 1].count()\n",
    "num_items_constant_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the data can sometimes be noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"4\">\n",
    "  <li><b>What was the variance of the number of sold items per day sequence for the shop with `shop_id = 25` in December, 2014? Do not count the items, that were sold but returned back later.</b></li>\n",
    "</ol>\n",
    "\n",
    "* Fill `total_num_items_sold` and `days` arrays, and plot the sequence with the code below.\n",
    "* Then compute variance. Remember, there can be differences in how you normalize variance (biased or unbiased estimate, see [link](https://math.stackexchange.com/questions/496627/the-difference-between-unbiased-biased-estimator-variance)). Compute ***unbiased*** estimate (use the right value for `ddof` argument in `pd.var` or `np.var`). \n",
    "* If there were no sales at a given day, ***do not*** impute missing value with zero, just ignore that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "shop_id = 25\n",
    "\n",
    "transactions['datetime'] = pd.to_datetime(transactions.date, format=\"%d.%m.%Y\")\n",
    "date_mask = (transactions.datetime >= '2014-12-01') & (transactions.datetime <= '2014-12-31')\n",
    "shop_mask = transactions.shop_id == shop_id\n",
    "december_shop_trans = transactions.loc[date_mask & shop_mask]\n",
    "\n",
    "#sold_items = december_shop_trans.loc[december_shop_trans[\"item_cnt_day\"] > 0]\n",
    "#returned_items = december_shop_trans.loc[december_shop_trans[\"item_cnt_day\"] < 0]\n",
    "\n",
    "#joined_df = sold_items.join(returned_items.set_index([\"datetime\", \"item_id\"])[\"item_cnt_day\"], \n",
    "#                                               on=[\"datetime\",\"item_id\"], how=\"left\", \n",
    "#                            lsuffix=\"_sold\", rsuffix=\"_returned\")\n",
    "\n",
    "#joined_df[\"total_cnt\"] = joined_df[\"item_cnt_day_sold\"] + joined_df[\"item_cnt_day_returned\"].fillna(0)\n",
    "\n",
    "#item_sold_per_day = joined_df.reset_index().groupby(by=\"datetime\")[\"total_cnt\"].sum()\n",
    "\n",
    "total_num_items_sold = december_shop_trans.groupby(\"datetime\")[\"item_cnt_day\"].sum()\n",
    "days = [d.astype(datetime) for d in total_num_items_sold .index.values]\n",
    "\n",
    "# Plot it\n",
    "plt.plot(days, total_num_items_sold)\n",
    "plt.ylabel('Num items')\n",
    "plt.xlabel('Day')\n",
    "plt.title(\"Daily revenue for shop_id = 25\")\n",
    "plt.show()\n",
    "\n",
    "total_num_items_sold_var = np.var(total_num_items_sold.values, ddof=1)\n",
    "total_num_items_sold_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! :)"
   ]
  }
 ],
 "metadata": {
  "hw_version": "1.0.0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
