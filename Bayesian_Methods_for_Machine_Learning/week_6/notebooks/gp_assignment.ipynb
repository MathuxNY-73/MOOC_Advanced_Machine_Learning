{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NrHfTDyt6TMG"
   },
   "source": [
    "# Gaussian processes and Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxDRoppa6TMK"
   },
   "source": [
    "In this assignment you will learn how to use <a href=\"http://sheffieldml.github.io/GPy/\">GPy</a> and <a href=\"http://sheffieldml.github.io/GPyOpt/\">GPyOpt</a> libraries to deal with gaussian processes. These libraries provide quite simple and inuitive interfaces for training and inference, and we will try to get familiar with them in a few tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cr9w3wbF6TMM"
   },
   "source": [
    "### Setup\n",
    "Load auxiliary files and then install and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etfETFjO6TMk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "import GPyOpt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "import sklearn.datasets\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkxQnNSl6TM3"
   },
   "source": [
    "## Gaussian processes: GPy (<a href=\"http://pythonhosted.org/GPy/\">documentation</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "9m363FFu6TM5"
   },
   "source": [
    "We will start with a simple regression problem, for which we will try to fit a Gaussian Process with RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdCm9E3c6TM7"
   },
   "outputs": [],
   "source": [
    "def generate_points(n=25, noise_variance=0.0036):\n",
    "    np.random.seed(777)\n",
    "    X = np.random.uniform(-3., 3., (n, 1))\n",
    "    y = np.sin(X) + np.random.randn(n, 1) * noise_variance**0.5\n",
    "    return X, y\n",
    "    \n",
    "def generate_noise(n=25, noise_variance=0.0036):\n",
    "    np.random.seed(777)\n",
    "    X = np.random.uniform(-3., 3., (n, 1))\n",
    "    y = np.random.randn(n, 1) * noise_variance**0.5\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "AIucv9NP6TND",
    "outputId": "c19b2081-a8a8-435e-db0f-5e5a6a4906e3"
   },
   "outputs": [],
   "source": [
    "# Create data points\n",
    "X, y = generate_points()\n",
    "plt.plot(X, y, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJgdjy2K6TNH"
   },
   "source": [
    "To fit a Gaussian Process, you will need to define a kernel. For Gaussian (GBF) kernel you can use `GPy.kern.RBF` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9VqhPy96TNJ"
   },
   "source": [
    "<b> Task 1.1: </b> Create RBF kernel with variance 1.5 and length-scale parameter 2 for 1D samples and compute value of the kernel between points `X[5]` and `X[9]`. Submit a single number. \n",
    "<br><b>Hint:</b> use `.K` property of kernel object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "srU1pqXo6TNK",
    "outputId": "c2b9ab8c-9d99-4ce7-f5ec-37a38d250bc3"
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1, variance=1.5, lengthscale=2.0) ### YOUR CODE HERE\n",
    "kernel_59 = kernel.K(X[5].reshape((1,1)), X[9].reshape((1,1)))[0,0]\n",
    "kernel_59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxWXD0vG6TNR"
   },
   "source": [
    "<b> Task 1.2: </b> Fit GP into generated data. Use kernel from previous task. Submit predicted mean and vairance at position $x=1$.\n",
    "<br><b>Hint:</b> use `GPy.models.GPRegression` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "GcI-b2LW6TNS",
    "outputId": "d39c1efd-57a3-459d-d228-a97fa28be0f1"
   },
   "outputs": [],
   "source": [
    "model = GPy.models.GPRegression(X,y, kernel=kernel)### YOUR CODE HERE\n",
    "inference = model.predict(np.array([[1]]))\n",
    "mean = np.asscalar(inference[0])### YOUR CODE HERE\n",
    "variance = np.asscalar(inference[1])### YOUR CODE HERE\n",
    "mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "8HgBVuqT6TNX",
    "outputId": "0832984d-883c-4a2c-96bd-db929204155b"
   },
   "outputs": [],
   "source": [
    "model.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3P5p-ZL6TNg"
   },
   "source": [
    "We see that the model didn't fit the data quite well. Let's try to fit kernel and noise parameters automatically as discussed in the lecture! You can see the current parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "qJ-k-QKx6TNi",
    "outputId": "3e195fe6-848c-49f9-bb7b-2c5ab409491c"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzKkmVzh6TNq"
   },
   "source": [
    "<b> Task 1.3: </b> Optimize length-scale, variance and noise component of the model and submit optimal length-scale value of the kernel. \n",
    "<br><b>Hint:</b> Use `.optimize()` function of the model and `.lengthscale` property of the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZffCbme66TNr",
    "outputId": "75bf6769-b94d-4b81-fdb0-c7bb896f8e93"
   },
   "outputs": [],
   "source": [
    "model.optimize(max_iters=500)\n",
    "kernel.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "J_zla0NL6TN0",
    "outputId": "e5df4866-6a5a-43af-afb9-f41caf1f3601"
   },
   "outputs": [],
   "source": [
    "model.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sv5_QYYs6TN5"
   },
   "source": [
    "As you see, the process generates outputs just right. Let's see if GP can figure out itself when we try to fit it into noise or signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnZ3vKlw6TN7"
   },
   "source": [
    "<b> Task 1.4: </b> Generate two datasets: sinusoid wihout noise and samples from gaussian noise. Optimize kernel parameters and submit optimal values of noise component.\n",
    "<br><b>Note:</b> generate data only using ```generate_points(n, noise_variance)``` and ```generate_noise(n, noise_variance)``` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPenDNIr6TN9"
   },
   "outputs": [],
   "source": [
    "X, y = generate_noise(noise_variance=10)\n",
    "gp_noisy = GPy.models.GPRegression(X, y, kernel=kernel)\n",
    "gp_noisy.optimize()\n",
    "noise = gp_noisy.Gaussian_noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZU1t4V6R6TOF"
   },
   "outputs": [],
   "source": [
    "X, y = generate_points(noise_variance=0)\n",
    "gp_pure = GPy.models.GPRegression(X, y, kernel=kernel)\n",
    "gp_pure.optimize()\n",
    "just_signal = gp_pure.Gaussian_noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jJ74U4r16TOL",
    "outputId": "8d6221bb-a203-42af-cfe8-76113857b15d"
   },
   "outputs": [],
   "source": [
    "noise, just_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZByrgGsS6TOP"
   },
   "source": [
    "## Sparse GP\n",
    "Now let's consider the speed of GP. We will generate a dataset of 3000 points and measure the time that is consumed for prediction of mean and variance for each point. We will then try to use inducing inputs and find the optimal number of points according to quality-time tradeoff.\n",
    "\n",
    "For the sparse model with inducing points, you should use ```GPy.models.SparseGPRegression``` class. You can set the number of inducing inputs with parameter ```num_inducing``` and optimize their positions and values with ```.optimize()``` call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FrXom83l6TOR"
   },
   "source": [
    "<b>Task 1.5</b>: Create a dataset of 1000 points and fit GPRegression. Measure time for predicting mean and variance at position $x=1$. Then fit `SparseGPRegression` with 10 inducing inputs and repeat the experiment. Report speedup as a ratio between consumed time without and with inducing inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k66ojuf-6TOU"
   },
   "outputs": [],
   "source": [
    "X, y = generate_points(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z-hPAAqD6TOe",
    "outputId": "79d34c1c-095f-4fe9-bf93-2b10a7eeefb2"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gp_time = GPy.models.GPRegression(X, y, kernel=kernel)\n",
    "gp_time.optimize()\n",
    "gp_pred = gp_time.predict(np.array([1]).reshape(1,1))\n",
    "print(gp_pred)\n",
    "time_gp = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mv8Wy6Gy6TOm",
    "outputId": "6dc3c64f-b603-40d5-d794-47006acfc68c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sparse_gp = GPy.models.SparseGPRegression(X, y, kernel=kernel, num_inducing=10)\n",
    "sparse_gp.optimize()\n",
    "sparse_gp_pred = sparse_gp.predict(np.array([1]).reshape(1,1))\n",
    "print(sparse_gp_pred)\n",
    "time_sgp = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "EQTkERYR6TOv",
    "outputId": "70dd1ad1-009f-413b-afee-a927f5d0dc89"
   },
   "outputs": [],
   "source": [
    "gp_time.plot()\n",
    "sparse_gp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5xNCDtGJ6TOz",
    "outputId": "d873aec6-0d52-41ad-cd3e-85c74f5c6363"
   },
   "outputs": [],
   "source": [
    "time_gp / time_sgp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKpvWQWp6TO2"
   },
   "source": [
    "## Bayesian optimization: GPyOpt (<a href=\"http://pythonhosted.org/GPyOpt/\">documentation</a>, <a href=\"http://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/index.ipynb\">tutorials</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xRO_xj7T6TO3"
   },
   "source": [
    "In this part of the assignment, we will try to find optimal hyperparameters to XGBoost model! We will use data from a small competition to speed things up, but keep in mind that the approach works even for large datasets.\n",
    "\n",
    "We will use diabetes dataset provided in sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkIfU2ba6TO7"
   },
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.load_diabetes()\n",
    "X = dataset['data']\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSXJaPOe6TPB"
   },
   "source": [
    "We will use cross-validation score to estimate accuracy and our goal will be to tune: ```max_depth```, ```learning_rate```, ```n_estimators``` parameters. The baseline MSE with default XGBoost parameters is $0.2$. Let's see if we can do better. First, we have to define optimization function and domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSVA8gKP6TPC"
   },
   "outputs": [],
   "source": [
    "# Score. Optimizer will try to find minimum, so we will add a \"-\" sign.\n",
    "def f(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = -cross_val_score(\n",
    "        XGBRegressor(learning_rate=parameters[0],\n",
    "                     max_depth=int(parameters[2]),\n",
    "                     n_estimators=int(parameters[3]),\n",
    "                     gamma=int(parameters[1]),\n",
    "                     min_child_weight = parameters[4]), \n",
    "        X, y, scoring='neg_mean_squared_error'\n",
    "    ).mean()\n",
    "    score = np.array(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "nLpdAfHH6TPJ",
    "outputId": "fafa68d9-d297-40b0-e05c-267ee53b9b86"
   },
   "outputs": [],
   "source": [
    "baseline = -cross_val_score(\n",
    "    XGBRegressor(), X, y, scoring='neg_mean_squared_error'\n",
    ").mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtqXl0Jc6TPQ"
   },
   "outputs": [],
   "source": [
    "# Bounds (NOTE: define continuous variables first, then discrete!)\n",
    "bounds = [\n",
    "    {'name': 'learning_rate',\n",
    "     'type': 'continuous',\n",
    "     'domain': (0, 1)},\n",
    "\n",
    "    {'name': 'gamma',\n",
    "     'type': 'continuous',\n",
    "     'domain': (0, 5)},\n",
    "\n",
    "    {'name': 'max_depth',\n",
    "     'type': 'discrete',\n",
    "     'domain': (1, 50)},\n",
    "\n",
    "    {'name': 'n_estimators',\n",
    "     'type': 'discrete',\n",
    "     'domain': (1, 300)},\n",
    "\n",
    "    {'name': 'min_child_weight',\n",
    "     'type': 'discrete',\n",
    "     'domain': (1, 10)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "OL2XN6Eg6TPW",
    "outputId": "805094b6-af0a-4d0b-d254-d7f87cdcbcc1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(\n",
    "    f=f, domain=bounds,\n",
    "    acquisition_type ='MPI',\n",
    "    acquisition_par = 0.1,\n",
    "    exact_eval=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7aWnWgk76TPZ",
    "outputId": "d1bad337-91ec-4ea2-837e-e0a6a31ac4f0"
   },
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "max_time = 60\n",
    "optimizer.run_optimization(max_iter, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "rJZvvOON6TPx",
    "outputId": "e57e08b6-0d8e-45b1-a853-375f1c2e72c9"
   },
   "outputs": [],
   "source": [
    "optimizer.plot_convergence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4rtECdX6TP3"
   },
   "source": [
    "Best values of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ON31H0ZW6TP4",
    "outputId": "55320c6a-7c80-41fc-8ce0-05c1779f30ff"
   },
   "outputs": [],
   "source": [
    "optimizer.X[np.argmin(optimizer.Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4CoYomX96TQC",
    "outputId": "218e3700-150e-4155-a8a9-e7a4e458e3fe"
   },
   "outputs": [],
   "source": [
    "print('MSE:', np.min(optimizer.Y),\n",
    "      'Gain:', baseline/np.min(optimizer.Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zuUiSeW6TQF"
   },
   "source": [
    "We were able to get 9% boost without tuning parameters by hand! Let's see if you can do the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ou0g0ACB6TQK"
   },
   "source": [
    "<b>Task 2.1:</b> Tune SVR model. Find optimal values for three parameters: `C`, `epsilon` and `gamma`. Use range (1e-5, 1000) for `C`, (1e-5, 10) for `epsilon` and `gamma`. Use MPI as an acquisition function with weight 0.1. Submit the optimal value of epsilon that was found by a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KKDkT2TFZ5u3",
    "outputId": "348d5944-cc6e-4a71-c7a1-5e0b8a1475bf"
   },
   "outputs": [],
   "source": [
    "baseline = -cross_val_score(SVR(gamma = 'auto'), X, y, scoring='neg_mean_squared_error').mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWzm3h57ZNx2"
   },
   "outputs": [],
   "source": [
    "def f_model(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = -cross_val_score(\n",
    "        SVR(gamma=float(parameters[0]),\n",
    "            C=float(parameters[1]),\n",
    "            epsilon=float(parameters[2])), \n",
    "        X, y, scoring='neg_mean_squared_error'\n",
    "    ).mean()\n",
    "    score = np.array(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVUFDinwZXaG"
   },
   "outputs": [],
   "source": [
    "svr_bounds = [\n",
    "    {'name': 'gamma',\n",
    "     'type': 'continuous',\n",
    "     'domain': (1e-5, 10)},\n",
    "    {'name': 'C',\n",
    "     'type': 'continuous',\n",
    "     'domain': (1e-5, 1000)},\n",
    "    {'name': 'epsilon',\n",
    "     'type': 'continuous',\n",
    "     'domain': (1e-5, 10)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf6dYIAjZO3c"
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(\n",
    "    f=f_model, domain=svr_bounds,\n",
    "    acquisition_type ='MPI',\n",
    "    acquisition_par = 0.1,\n",
    "    exact_eval=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "ML_2kSy1Z0eL",
    "outputId": "9f4f4332-1936-4da0-f41b-7d6ccf2284ca"
   },
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "max_time = 60\n",
    "optimizer.run_optimization(max_iter, max_time)\n",
    "optimizer.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-YePyinXbjtx",
    "outputId": "1bee39a7-f97b-4751-d689-b4db7810ceaf"
   },
   "outputs": [],
   "source": [
    "optimizer.X[np.argmin(optimizer.Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "HSS_Di9qaceS",
    "outputId": "bf638849-010b-4d61-cece-369697f926a6"
   },
   "outputs": [],
   "source": [
    "res = dict(best_eps=optimizer.X[np.argmin(optimizer.Y)][2],\n",
    "    MSE=np.min(optimizer.Y),\n",
    "     Gain=baseline/np.min(optimizer.Y)*100)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zp0R5rHG6TQK",
    "outputId": "75cd3488-0919-405c-b904-70c87ccd386f"
   },
   "outputs": [],
   "source": [
    "best_epsilon = res['best_eps']### YOUR CODE HERE\n",
    "best_epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z65YEJ5k6TQQ"
   },
   "source": [
    "<b>Task 2.2:</b> For the model above submit boost in improvement that you got after tuning hyperparameters (output percents) [e.g. if baseline MSE was 40 and you got 20, output number 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1O6SSlQd6TQS",
    "outputId": "df455b21-1693-4c15-b9d0-2ed747450810"
   },
   "outputs": [],
   "source": [
    "performance_boost = res['Gain']### YOUR CODE HERE\n",
    "performance_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKGvEjhyhYFX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of gp_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
